{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3dYt68vNJM6"
   },
   "source": [
    "# MAIS202 Project\n",
    "### Gargi Singh and Jehan Dastoor\n",
    "\n",
    "![To make your day better :)](https://media.gettyimages.com/videos/close-up-baboon-making-noise-on-telephone-video-id712-17?s=640x640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l6sN8-_rMc-B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in /opt/anaconda3/lib/python3.7/site-packages (2.5.0.dev20210302)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (0.11.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (0.36.2)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (0.4.0)\n",
      "Requirement already satisfied: tf-estimator-nightly~=2.5.0.dev in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (2.5.0.dev2021030201)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: tb-nightly~=2.5.0.a in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (2.5.0a20210302)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (3.14.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (1.34.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (1.12)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/anaconda3/lib/python3.7/site-packages (from tf-nightly) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tf-nightly) (1.1.2)\n",
      "Requirement already satisfied: cached-property in /opt/anaconda3/lib/python3.7/site-packages (from h5py~=3.1.0->tf-nightly) (1.5.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (52.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2019.11.28)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jehandastoor/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRH2BszSMypU"
   },
   "source": [
    "The idea of the project is to categorize skin lesions based on the kind of cancer they are. The project will consist of a few major components:\n",
    "\n",
    "1) Importing the data\n",
    "\n",
    "2) Pre-processing the images by transformation (to increase the size of the dataset).\n",
    "\n",
    "3) Creating our model, i.e. deciding our layers that we are going to use (possibly based off an already built tensorflow model).\n",
    "\n",
    "4) Training the model\n",
    "\n",
    "5) Testing the model using our validation data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60Em2HKOPohX"
   },
   "source": [
    "## 1. Importing and pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames belonging to 4 classes.\n",
      "Found 2003 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Importing our data\n",
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "traindf = pd.read_csv(\"ISIC2018_Task3_Training_LesionGroupings.csv\")\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn+\".jpg\"\n",
    "\n",
    "traindf[\"image\"]=traindf[\"image\"].apply(append_ext)\n",
    "datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                             validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=traindf,\n",
    "                                              directory=\"./ISIC2018_Task3_Training_Input/\",\n",
    "                                              x_col=\"image\",\n",
    "                                              y_col=\"diagnosis_confirm_type\",\n",
    "                                              subset=\"training\",\n",
    "                                              batch_size=32,\n",
    "                                              color_mode=\"rgb\",\n",
    "                                              shuffle=True,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(600,450))\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(dataframe=traindf,\n",
    "                                              directory=\"./ISIC2018_Task3_Training_Input/\",\n",
    "                                              x_col=\"image\",\n",
    "                                              y_col=\"diagnosis_confirm_type\",\n",
    "                                              subset=\"validation\",\n",
    "                                              batch_size=32,\n",
    "                                              color_mode=\"rgb\",\n",
    "                                              shuffle=True,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(600,450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-4Or0WxKaNce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "#Running the Model\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        epochs=10,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
